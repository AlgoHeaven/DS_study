{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch15_다중회귀분석(5).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEe0v32fuSIt",
        "colab_type": "text"
      },
      "source": [
        "# 적합성\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M51xBxuNuW9Z",
        "colab_type": "text"
      },
      "source": [
        "- 다중 회귀 분석 모델은 단순 회귀 분석 모델보다 언제나 작은 오류를 가짐\n",
        "- 다중 회귀 분석 모델에서는 각 계수의 표준 오차를 봐야함 -> 추정된 beta 의 계수가 얼마나 확실한지 알려줌\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBLIEvBBzJPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import tqdm\n",
        "from typing import List"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs85ma8bw_Yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs: List[List[float]] = [[1.,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]\n",
        "y: List[float] = [1,10,5,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdqpWBlT3ZxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x: List[Vector] = [[1.,49,4,0],[1,41,9,0],[1,40,8,0]]\n",
        "y: List[float] = [1,42,5,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se9FG7XJ12rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def least_squares_fit(xs: List[Vector],\n",
        "                      ys: List[float],\n",
        "                      learning_rate: float = 0.001,\n",
        "                      num_steps: int = 100,\n",
        "                      batch_size: int = 1) -> Vector:\n",
        "    \"\"\"\n",
        "    Find the beta that minimizes the sum of squared errors\n",
        "    assuming the model y = dot(x, beta).\n",
        "    \"\"\"\n",
        "    # Start with a random guess\n",
        "    guess = [random.random() for _ in xs[0]]\n",
        "\n",
        "    for _ in tqdm.trange(num_steps, desc=\"least squares fit\"):\n",
        "        for start in range(0, len(xs), batch_size):\n",
        "            batch_xs = xs[start:start+batch_size]\n",
        "            batch_ys = ys[start:start+batch_size]\n",
        "            # print([sqerror_gradient(x, y, guess) for x, y in zip(batch_xs, batch_ys)])\n",
        "            gradient = vector_mean([sqerror_gradient(x, y, guess) for x, y in zip(batch_xs, batch_ys)])\n",
        "            guess = gradient_step(guess, gradient, -learning_rate)\n",
        "    return guess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4yPy-pDuGoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiple_r_squared(xs: List[Vector], ys: Vector, beta: Vector) -> float:\n",
        "    print(\"각 변수들의 squared error\",[error(x, y, beta) ** 2 for x, y in zip(xs, ys)])\n",
        "    print(\"total sum of squares y : \",total_sum_of_squares(ys))\n",
        "    sum_of_squared_errors = sum(error(x, y, beta) ** 2 for x, y in zip(xs, ys))\n",
        "    return 1.0 - sum_of_squared_errors / total_sum_of_squares(ys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kME8Ob8J18FK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aaaeb5ce-4759-405f-f6d8-651eff33c46a"
      },
      "source": [
        "beta: Vector = least_squares_fit(x, y)\n",
        "print(beta)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "least squares fit: 100%|██████████| 10/10 [00:00<00:00, 7672.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1.846655546408727e+45, 7.382190895303069e+46, 1.4710384877168176e+46, 0.6809473591935791]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0MdgWxZ6MKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "04aa036a-79d5-44b3-a2bd-1cb2a92b2d74"
      },
      "source": [
        "multiple_r_squared(x, y, beta)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "각 변수들의 squared error [1.3527402514955678e+97, 9.99153148334519e+96, 9.439679198367797e+96]\n",
            "total sum of squares y :  1214.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2.714877528555903e+94"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZOU2GkDyUTW",
        "colab_type": "text"
      },
      "source": [
        "### 필요 함수\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbjOpdwlyY1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scratch.linear_algebra import dot, Vector\n",
        "\n",
        "Vector = List[float]\n",
        "\n",
        "def dot(v: Vector, w: Vector) -> float:\n",
        "    \"\"\"Computes v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
        "    assert len(v) == len(w), \"vectors must be same length\"\n",
        "\n",
        "    return sum(v_i * w_i for v_i, w_i in zip(v, w))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23y_g9u2yzXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scratch.linear_algebra import vector_mean\n",
        "# from scratch.gradient_descent import gradient_step\n",
        "\n",
        "def vector_sum(vectors: List[Vector]) -> Vector:\n",
        "    \"\"\"Sums all corresponding elements\"\"\"\n",
        "    # Check that vectors is not empty\n",
        "    assert vectors, \"no vectors provided!\"\n",
        "\n",
        "    # Check the vectors are all the same size\n",
        "    num_elements = len(vectors[0])\n",
        "    assert all(len(v) == num_elements for v in vectors), \"different sizes!\"\n",
        "\n",
        "    # the i-th element of the result is the sum of every vector[i]\n",
        "    return [sum(vector[i] for vector in vectors) for i in range(num_elements)]\n",
        "\n",
        "def vector_mean(vectors: List[Vector]) -> Vector:\n",
        "    \"\"\"Computes the element-wise average\"\"\"\n",
        "    n = len(vectors)\n",
        "    return scalar_multiply(1/n, vector_sum(vectors))\n",
        "\n",
        "def gradient_step(v: Vector, gradient: Vector, step_size: float) -> Vector:\n",
        "    \"\"\"Moves `step_size` in the `gradient` direction from `v`\"\"\"\n",
        "    assert len(v) == len(gradient)\n",
        "    step = scalar_multiply(step_size, gradient)\n",
        "    return add(v, step)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXDbbmxuzlbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scratch.linear_algebra import add, scalar_multiply\n",
        "\n",
        "def scalar_multiply(c: float, v: Vector) -> Vector:\n",
        "    \"\"\"Multiplies every element by c\"\"\"\n",
        "    return [c * v_i for v_i in v]\n",
        "def add(v: Vector, w: Vector) -> Vector:\n",
        "    \"\"\"Adds corresponding elements\"\"\"\n",
        "    assert len(v) == len(w), \"vectors must be the same length\"\n",
        "    return [v_i + w_i for v_i, w_i in zip(v, w)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYnKlAR20Iwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scratch.statistics import de_mean\n",
        "# from scratch.simple_linear_regression import total_sum_of_squares\n",
        "\n",
        "def mean(xs: List[float]) -> float:\n",
        "    return sum(xs) / len(xs)\n",
        "    \n",
        "def de_mean(xs: List[float]) -> List[float]:\n",
        "    \"\"\"Translate xs by subtracting its mean (so the result has mean 0)\"\"\"\n",
        "    x_bar = mean(xs)\n",
        "    return [x - x_bar for x in xs]\n",
        "\n",
        "def total_sum_of_squares(y: Vector) -> float:\n",
        "    \"\"\"the total squared variation of y_i's from their mean\"\"\"\n",
        "    return sum(v ** 2 for v in de_mean(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFKiyaYG0uG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(x: Vector, beta: Vector) -> float:\n",
        "    \"\"\"assumes that the first element of x is 1\"\"\"\n",
        "    return dot(x, beta)\n",
        "    \n",
        "def error(x: Vector, y: float, beta: Vector) -> float:\n",
        "    return predict(x, beta) - y\n",
        "\n",
        "def squared_error(x: Vector, y: float, beta: Vector) -> float:\n",
        "    return error(x, y, beta) ** 2\n",
        "\n",
        "def sqerror_gradient(x: Vector, y: float, beta: Vector) -> Vector:\n",
        "    err = error(x, y, beta)\n",
        "    return [2 * err * x_i for x_i in x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXcK5PxM2NgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}