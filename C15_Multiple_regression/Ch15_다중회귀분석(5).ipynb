{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch15_다중회귀분석(5).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEe0v32fuSIt",
        "colab_type": "text"
      },
      "source": [
        "# 적합성\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M51xBxuNuW9Z",
        "colab_type": "text"
      },
      "source": [
        "- 다중 회귀 분석 모델은 단순 회귀 분석 모델보다 언제나 작은 오류를 가짐\n",
        "- 다중 회귀 분석 모델에서는 각 계수의 표준 오차를 봐야함 -> 추정된 beta 의 계수가 얼마나 확실한지 알려줌\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBLIEvBBzJPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import tqdm\n",
        "from typing import List"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs85ma8bw_Yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs: List[List[float]] = [[1.,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdqpWBlT3ZxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = [[1,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]\n",
        "daily_minutes_good = [68.77,51.25,52.08,38.36,44.54,57.13,51.4,41.42,31.22,34.76,54.01,38.79,47.59,49.1,27.66,41.03,36.73,48.65,28.12,46.62,35.57,32.98,35,26.07,23.77,39.73,40.57,31.65,31.21,36.32,20.45,21.93,26.02,27.34,23.49,46.94,30.5,33.8,24.23,21.4,27.94,32.24,40.57,25.07,19.42,22.39,18.42,46.96,23.72,26.41,26.97,36.76,40.32,35.02,29.47,30.2,31,38.11,38.18,36.31,21.03,30.86,36.07,28.66,29.08,37.28,15.28,24.17,22.31,30.17,25.53,19.85,35.37,44.6,17.23,13.47,26.33,35.02,32.09,24.81,19.33,28.77,24.26,31.98,25.73,24.86,16.28,34.51,15.23,39.72,40.8,26.06,35.76,34.76,16.13,44.04,18.03,19.65,32.62,35.59,39.43,14.18,35.24,40.13,41.82,35.45,36.07,43.67,24.61,20.9,21.9,18.79,27.61,27.21,26.61,29.77,20.59,27.53,13.82,33.2,25,33.1,36.65,18.63,14.87,22.2,36.81,25.53,24.62,26.25,18.21,28.08,19.42,29.79,32.8,35.99,28.32,27.79,35.88,29.06,36.28,14.1,36.63,37.49,26.9,18.58,38.48,24.48,18.95,33.55,14.24,29.04,32.51,25.63,22.22,19,32.73,15.16,13.9,27.2,32.01,29.27,33,13.74,20.42,27.32,18.23,35.35,28.48,9.08,24.62,20.12,35.26,19.92,31.02,16.49,12.16,30.7,31.22,34.65,13.13,27.51,33.2,31.57,14.1,33.42,17.44,10.12,24.42,9.82,23.39,30.93,15.03,21.67,31.09,33.29,22.61,26.89,23.48,8.38,27.81,32.35,23.84]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se9FG7XJ12rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def least_squares_fit(xs: List[Vector],\n",
        "                      ys: List[float],\n",
        "                      learning_rate: float = 0.001,\n",
        "                      num_steps: int = 100,\n",
        "                      batch_size: int = 1) -> Vector:\n",
        "    \"\"\"\n",
        "    Find the beta that minimizes the sum of squared errors\n",
        "    assuming the model y = dot(x, beta).\n",
        "    \"\"\"\n",
        "    # Start with a random guess\n",
        "    guess = [random.random() for _ in xs[0]]\n",
        "\n",
        "    for _ in tqdm.trange(num_steps, desc=\"least squares fit\"):\n",
        "        for start in range(0, len(xs), batch_size):\n",
        "            batch_xs = xs[start:start+batch_size]\n",
        "            batch_ys = ys[start:start+batch_size]\n",
        "            # print([sqerror_gradient(x, y, guess) for x, y in zip(batch_xs, batch_ys)])\n",
        "            gradient = vector_mean([sqerror_gradient(x, y, guess) for x, y in zip(batch_xs, batch_ys)])\n",
        "            guess = gradient_step(guess, gradient, -learning_rate)\n",
        "    return guess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4yPy-pDuGoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiple_r_squared(xs: List[Vector], ys: Vector, beta: Vector) -> float:\n",
        "    print(\"각 변수들의 squared error\",[error(x, y, beta) ** 2 for x, y in zip(xs, ys)])\n",
        "    print(\"total sum of squares y : \",total_sum_of_squares(ys))\n",
        "    sum_of_squared_errors = sum(error(x, y, beta) ** 2 for x, y in zip(xs, ys))\n",
        "    return 1.0 - sum_of_squared_errors / total_sum_of_squares(ys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kME8Ob8J18FK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c59bc731-58f5-403a-c524-23690c9d9eec"
      },
      "source": [
        "beta: Vector = least_squares_fit(x, daily_minutes_good)\n",
        "print(beta)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "least squares fit: 100%|██████████| 100/100 [00:00<00:00, 540.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[26.84611702240796, 1.1831239703249308, -1.733752772824939, 3.9037304827723456]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0MdgWxZ6MKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "672c9bcf-e993-41c6-9f6e-1108f98f7391"
      },
      "source": [
        "multiple_r_squared(x, daily_minutes_good, beta)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "각 변수들의 squared error [83.06828576787125, 72.25722263569418, 67.5857231623096, 58.701641428458295, 29.354373200789663, 29.57488501613475, 52.93705987902138, 62.49649479339286, 1.7386361614857677, 0.23782563215395056, 230.0958470825577, 0.36206486298185264, 8.982149396320835, 63.593112267339805, 23.008399650816347, 5.663698430839969, 24.463903569201154, 66.5370427584331, 3.882709564707814, 128.3299833727319, 10.171143924053943, 0.36621765470318857, 36.52515736260934, 3.288036071326224, 0.4849983507520514, 7.7640029316715795, 13.15074829091328, 26.100988813934634, 66.20130160968769, 0.3888818899881108, 61.22812241384611, 40.2569957512715, 1.47055751046094, 36.00205206034731, 22.894694674503697, 68.27127387904113, 0.24148097573674104, 0.10491224182974074, 56.43533693005037, 0.24054885349048466, 36.59696083069536, 27.606961847207188, 9.460344143370529, 4.087336063328407, 0.542734296929282, 1.5232757378454764, 108.27378284588995, 167.2695450687682, 3.3472246619178914, 39.1036980183097, 2.5986621752653147, 7.470780146290244, 7.984960521036696, 19.898543362636318, 5.65623422156065, 0.12904020391033438, 31.832577610069745, 49.00209349090402, 28.477130386995473, 48.079001193206416, 0.10411345753160084, 3.9346818111896784, 24.603083394356986, 1.0356218600532106, 44.07517110072796, 0.9387501864898278, 29.455952497735616, 27.002769833684134, 28.433902355263687, 6.3890401989874235, 0.8634515749555124, 43.68180157329194, 0.058571349924273486, 167.43119674713517, 16.224482965456723, 18.6663494357099, 0.0166980540630581, 25.94143498443313, 4.679752252210001, 0.007145628975806022, 13.408159706539893, 33.388572861878586, 22.427708257148872, 4.215932081375673, 19.99911822004633, 4.621853960722626, 52.741643386871175, 56.25225372670732, 9.678855408318617, 33.352232267034665, 73.76906455889228, 0.9022145533839393, 12.594633919941, 0.6644518430614955, 32.24640068091911, 101.91183457178549, 4.181365152620364, 54.16738838758477, 3.1014231297310673, 0.2754555080849093, 46.004571515480116, 175.98873768544112, 18.717907975799672, 84.94239326938101, 32.548867121445205, 7.854942264374472, 26.58866478432164, 76.35763201182755, 12.590486814420794, 77.97695785700013, 19.035338983886117, 119.69358329743208, 4.496334773920278, 62.126875699094676, 1.9229465766116565, 11.750922178737634, 83.54794074161335, 4.842007776401103, 52.44210883621224, 3.012970262614777, 32.17226885731029, 0.009596516444783678, 11.916567657243691, 5.913127934931725, 45.45889521629687, 8.293402107310818, 1.762672083423334, 54.540947761915334, 4.811791120896647, 65.69401321406319, 2.7841206091152655, 32.132919545218606, 83.30819482664074, 1.5442230246019282, 7.194966042993144, 32.591709700753086, 29.469596050664137, 6.205504816038532, 14.939478516678582, 0.2628281755651263, 59.79414983316202, 56.43496987027286, 21.299721755433364, 79.97130567882577, 15.458373959523138, 28.267328442411106, 123.56082456521524, 5.368720672932003, 70.79890173406493, 0.969305930395588, 7.407605644015028, 0.003359488844303013, 26.479171963988062, 12.020435658256783, 11.631207072375021, 23.9776981078785, 0.027071225457045635, 76.32997545217644, 9.37395599179091, 13.189345637220002, 21.583380288843404, 2.4389502133283925, 0.18881923805876336, 141.38293323481068, 33.19009294001508, 5.422330923221654, 1.032404876252193, 55.28164694275344, 8.423592991547139, 71.1040288529161, 78.17092480460474, 6.799992424757886, 82.42670929755242, 20.4967312507078, 4.393616118029976, 1.0451391851033884, 28.647334632016893, 5.837517203361286, 0.026355143478483313, 10.677584406662598, 170.3308028290685, 19.562676673132962, 22.415812861360408, 9.638131792688853, 83.98270114448506, 44.733180893840014, 8.091500275025851, 130.19847962271706, 56.44474039175532, 67.94621304541498, 3.4579082074512595, 35.189094003355585, 1.6879115977900236, 28.524181811117213, 37.112946680409834, 23.276128993986408, 39.44849235336531, 25.431561302759462, 29.344438363230598, 172.93446246089053, 5.7083660092373325, 4.625860188900226, 0.33153687479210125]\n",
            "total sum of squares y :  19670.254088669957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.662147547389565"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZOU2GkDyUTW",
        "colab_type": "text"
      },
      "source": [
        "### 필요 함수\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbjOpdwlyY1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scratch.linear_algebra import dot, Vector\n",
        "\n",
        "Vector = List[float]\n",
        "\n",
        "def dot(v: Vector, w: Vector) -> float:\n",
        "    \"\"\"Computes v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
        "    assert len(v) == len(w), \"vectors must be same length\"\n",
        "\n",
        "    return sum(v_i * w_i for v_i, w_i in zip(v, w))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23y_g9u2yzXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scratch.linear_algebra import vector_mean\n",
        "# from scratch.gradient_descent import gradient_step\n",
        "\n",
        "def vector_sum(vectors: List[Vector]) -> Vector:\n",
        "    \"\"\"Sums all corresponding elements\"\"\"\n",
        "    # Check that vectors is not empty\n",
        "    assert vectors, \"no vectors provided!\"\n",
        "\n",
        "    # Check the vectors are all the same size\n",
        "    num_elements = len(vectors[0])\n",
        "    assert all(len(v) == num_elements for v in vectors), \"different sizes!\"\n",
        "\n",
        "    # the i-th element of the result is the sum of every vector[i]\n",
        "    return [sum(vector[i] for vector in vectors) for i in range(num_elements)]\n",
        "\n",
        "def vector_mean(vectors: List[Vector]) -> Vector:\n",
        "    \"\"\"Computes the element-wise average\"\"\"\n",
        "    n = len(vectors)\n",
        "    return scalar_multiply(1/n, vector_sum(vectors))\n",
        "\n",
        "def gradient_step(v: Vector, gradient: Vector, step_size: float) -> Vector:\n",
        "    \"\"\"Moves `step_size` in the `gradient` direction from `v`\"\"\"\n",
        "    assert len(v) == len(gradient)\n",
        "    step = scalar_multiply(step_size, gradient)\n",
        "    return add(v, step)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXDbbmxuzlbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scratch.linear_algebra import add, scalar_multiply\n",
        "\n",
        "def scalar_multiply(c: float, v: Vector) -> Vector:\n",
        "    \"\"\"Multiplies every element by c\"\"\"\n",
        "    return [c * v_i for v_i in v]\n",
        "def add(v: Vector, w: Vector) -> Vector:\n",
        "    \"\"\"Adds corresponding elements\"\"\"\n",
        "    assert len(v) == len(w), \"vectors must be the same length\"\n",
        "    return [v_i + w_i for v_i, w_i in zip(v, w)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYnKlAR20Iwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scratch.statistics import de_mean\n",
        "# from scratch.simple_linear_regression import total_sum_of_squares\n",
        "\n",
        "def mean(xs: List[float]) -> float:\n",
        "    return sum(xs) / len(xs)\n",
        "    \n",
        "def de_mean(xs: List[float]) -> List[float]:\n",
        "    \"\"\"Translate xs by subtracting its mean (so the result has mean 0)\"\"\"\n",
        "    x_bar = mean(xs)\n",
        "    return [x - x_bar for x in xs]\n",
        "\n",
        "def total_sum_of_squares(y: Vector) -> float:\n",
        "    \"\"\"the total squared variation of y_i's from their mean\"\"\"\n",
        "    return sum(v ** 2 for v in de_mean(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFKiyaYG0uG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(x: Vector, beta: Vector) -> float:\n",
        "    \"\"\"assumes that the first element of x is 1\"\"\"\n",
        "    return dot(x, beta)\n",
        "    \n",
        "def error(x: Vector, y: float, beta: Vector) -> float:\n",
        "    return predict(x, beta) - y\n",
        "\n",
        "def squared_error(x: Vector, y: float, beta: Vector) -> float:\n",
        "    return error(x, y, beta) ** 2\n",
        "\n",
        "def sqerror_gradient(x: Vector, y: float, beta: Vector) -> Vector:\n",
        "    err = error(x, y, beta)\n",
        "    return [2 * err * x_i for x_i in x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXcK5PxM2NgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}