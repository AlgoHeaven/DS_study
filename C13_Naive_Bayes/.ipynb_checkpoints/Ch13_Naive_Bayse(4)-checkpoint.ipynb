{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkkZPpLgROus"
   },
   "outputs": [],
   "source": [
    "!tar -xvf ./20021010_spam.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGzGtKIfUgkg"
   },
   "outputs": [],
   "source": [
    "!tar -xvf ./20021010_easy_ham.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OypPhaxbW7oa"
   },
   "outputs": [],
   "source": [
    "!tar -xvf ./20021010_hard_ham.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fz23-Ih2nzma"
   },
   "outputs": [],
   "source": [
    "import glob, re\n",
    "import math\n",
    "from typing import List, Tuple, Dict, Iterable, NamedTuple, TypeVar, Set\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "class Message(NamedTuple):\n",
    "    text: str\n",
    "    is_spam: bool\n",
    "\n",
    "X = TypeVar('X')\n",
    "def split_data(data, prob):\n",
    "    \"\"\"Split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    data = data[:]\n",
    "    random.shuffle(data)\n",
    "    cut = int(len(data) * prob)\n",
    "    return data[:cut], data[cut:]\n",
    "\n",
    "# 스팸 제목을 토큰화 시키기 위함\n",
    "def tokenize(text: str) -> Set[str]:\n",
    "    text = text.lower()                         # Convert to lowercase,\n",
    "    all_words = re.findall(\"[a-z0-9']+\", text)  # extract the words, and\n",
    "    return set(all_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xfFcDLuFjvn1"
   },
   "outputs": [],
   "source": [
    "path = 'Spam/*/*'\n",
    "\n",
    "data: List[Message] = []\n",
    "\n",
    "# 데이터 중 subject와 스팸 여부(is_spam)를 Message class에 넣는다\n",
    "# 해당 Message class 를 data에 append\n",
    "for filename in glob.glob(path):\n",
    "    is_spam = \"ham\" not in filename \n",
    "    with open(filename, errors='ignore') as email_file:\n",
    "        for line in email_file:\n",
    "            if line.startswith(\"Subject:\"):\n",
    "                subject = line.lstrip(\"Subject: \")\n",
    "                data.append(Message(subject, is_spam))\n",
    "                break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "FKIJa3-xnnv1",
    "outputId": "50e0ae32-826d-48b9-cb51-f692d69acb1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Message(text='CNET NEWS.COM: The tech side of homeland defense\\n', is_spam=False),\n",
       " Message(text='Your Daily Dilbert 07/13/2002\\n', is_spam=False),\n",
       " Message(text='[Lockergnome Tech Specialist]  Frequent Format\\n', is_spam=False),\n",
       " Message(text='CNET DIGITAL DISPATCH: Mac zealots unite\\n', is_spam=False),\n",
       " Message(text='Yahoo! News Story - Top Stories\\n', is_spam=False),\n",
       " Message(text='firewalls Digest V1 #33\\n', is_spam=False),\n",
       " Message(text=\"DayTips' Poem-a-Day: 09/13/02\\n\", is_spam=False),\n",
       " Message(text=\"Classic Novels, Aesop's Fables, Issue 49\\n\", is_spam=False),\n",
       " Message(text='Personal Finance: Resolutions You Can Keep\\n', is_spam=False),\n",
       " Message(text='[Lockergnome Tech Specialist]  Geothermal Caffeine\\n', is_spam=False)]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWbkUhSZz9h7"
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, k: float = 0.5) -> None:\n",
    "        self.k = k  # smoothing factor\n",
    "\n",
    "        self.tokens: Set[str] = set()\n",
    "        self.token_spam_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.token_ham_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.spam_messages = self.ham_messages = 0\n",
    "\n",
    "    def train(self, messages: Iterable[Message]) -> None:\n",
    "        for message in messages:\n",
    "            # 메시지 자체를 스팸 여부에 따라 count\n",
    "            if message.is_spam:\n",
    "                self.spam_messages += 1\n",
    "            else:\n",
    "                self.ham_messages += 1\n",
    "\n",
    "            # 단어 추출 뒤 스팸 여부에 따라 count\n",
    "            for token in tokenize(message.text):\n",
    "                self.tokens.add(token)\n",
    "                if message.is_spam:\n",
    "                    self.token_spam_counts[token] += 1\n",
    "                else:\n",
    "                    self.token_ham_counts[token] += 1\n",
    "\n",
    "    def _probabilities(self, token: str) -> Tuple[float, float]:\n",
    "        # P (token | spam) 과 P(token | not spam) 을 return\n",
    "        spam = self.token_spam_counts[token]\n",
    "        ham = self.token_ham_counts[token]\n",
    "\n",
    "        p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
    "        p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\n",
    "\n",
    "        return p_token_spam, p_token_ham\n",
    "\n",
    "    def predict(self, text: str) -> float:\n",
    "        text_tokens = tokenize(text)\n",
    "        log_prob_if_spam = log_prob_if_ham = 0.0\n",
    "\n",
    "        # train 된 단어들(vocabulary 에 있는 단어들)을 loop\n",
    "        for token in self.tokens:\n",
    "            prob_if_spam, prob_if_ham = self._probabilities(token)\n",
    "\n",
    "            # voca 에 있는 단어가 예측하기 위한 단어 집합(text_tokens)에 있는 경우 \n",
    "            # probabilities를 통해 구한 확률에 log 처리후 더해 줌\n",
    "            if token in text_tokens:\n",
    "                log_prob_if_spam += math.log(prob_if_spam)\n",
    "                log_prob_if_ham += math.log(prob_if_ham)\n",
    "\n",
    "            # text_tokens 에 있는 단어가 voca 에는 없음\n",
    "            else:\n",
    "                log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "                log_prob_if_ham += math.log(1.0 - prob_if_ham)\n",
    "\n",
    "        prob_if_spam = math.exp(log_prob_if_spam)\n",
    "        prob_if_ham = math.exp(log_prob_if_ham)\n",
    "        return prob_if_spam / (prob_if_spam + prob_if_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCb4X1ltywsk"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# train/test split\n",
    "train_messages, test_messages = split_data(data, 0.75)\n",
    "\n",
    "model = NaiveBayesClassifier()\n",
    "model.train(train_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4RCid6U1R3h"
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터에 대한 predict\n",
    "predictions = [(message, model.predict(message.text)) for message in test_messages]\n",
    "\n",
    "# confusion matrix\n",
    "# 실제 스팸이 스팸이라고 예측 (True, True) (TP)\n",
    "# 햄이 스팸으로 예측 (False, True) (FP)\n",
    "# 햄이 햄으로 예측 (False, False) (TN)\n",
    "# 실제 스팸이 햄으로 예측 (True, False) (FN)\n",
    "confusion_matrix = Counter((message.is_spam, spam_probability > 0.5) for message, spam_probability in predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "fZlOoZWnBh9j",
    "outputId": "09548581-5c4a-4eff-c51e-b29319477d31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(False, False): 675,\n",
       "         (False, True): 24,\n",
       "         (True, False): 51,\n",
       "         (True, True): 75})"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ARt8KRK1xAcx",
    "outputId": "9d708452-44ca-4905-9591-306abd312a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7575757575757576\n",
      "0.5952380952380952\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix\n",
    "# precision : TP / (TP + FP)\n",
    "# 스팸이라고 판단 한 것 중 실제 스팸인 비율\n",
    "print(cm[(True, True)] / (cm[(True, True)] + cm[(False, True)]))\n",
    "\n",
    "# recall : TP / (TP + FN)\n",
    "# 실제 스팸 중 스팸이라고 판단한 비율\n",
    "print(cm[(True, True)] / (cm[(True, True)] + cm[(True, False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_w0GH0ZK9s7T",
    "outputId": "79abdaf5-6319-4ac3-90e7-22e78952629b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spammiest_words ['clearance', 'account', 'per', 'sale', 'year', 'zzzz', 'systemworks', 'rates', 'money', 'adv']\n",
      "hammiest_words ['spambayes', 'users', 'zzzzteana', 'razor', 'sadev', 'ouch', 'perl', 'spam', 'bliss', 'selling']\n"
     ]
    }
   ],
   "source": [
    "def p_spam_given_token(token: str, model: NaiveBayesClassifier) -> float:\n",
    "    # naive bayse 를 통해 p(스팸 | 메시지가 해당 단어를 포함) 을 계산\n",
    "    prob_if_spam, prob_if_ham = model._probabilities(token)\n",
    "\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_ham)\n",
    "\n",
    "# 스팸일 확률에 따라 메시지를 오름차순 정렬\n",
    "words = sorted(model.tokens, key=lambda t: p_spam_given_token(t, model))\n",
    "\n",
    "# 스팸일 확률이 가장 높은 메시지\n",
    "print(\"spammiest_words\", words[-10:])\n",
    "\n",
    "# 스팸일 확률이 가장 낮은 메시지\n",
    "print(\"hammiest_words\", words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l6KhtT0I3nrz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch13_Naive_Bayse(4).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
