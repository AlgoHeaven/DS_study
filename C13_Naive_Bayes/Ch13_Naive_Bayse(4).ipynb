{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch13_Naive_Bayse(4).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkkZPpLgROus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xvf ./20021010_spam.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGzGtKIfUgkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xvf ./20021010_easy_ham.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OypPhaxbW7oa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xvf ./20021010_hard_ham.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz23-Ih2nzma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob, re\n",
        "import math\n",
        "from typing import List, Tuple, Dict, Iterable, NamedTuple, TypeVar, Set\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "class Message(NamedTuple):\n",
        "    text: str\n",
        "    is_spam: bool\n",
        "\n",
        "X = TypeVar('X')\n",
        "def split_data(data, prob):\n",
        "    \"\"\"Split data into fractions [prob, 1 - prob]\"\"\"\n",
        "    data = data[:]\n",
        "    random.shuffle(data)\n",
        "    cut = int(len(data) * prob)\n",
        "    return data[:cut], data[cut:]\n",
        "\n",
        "# 스팸 제목을 토큰화 시키기 위함\n",
        "def tokenize(text: str) -> Set[str]:\n",
        "    text = text.lower()                         # Convert to lowercase,\n",
        "    all_words = re.findall(\"[a-z0-9']+\", text)  # extract the words, and\n",
        "    return set(all_words) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfFcDLuFjvn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'Spam/*/*'\n",
        "\n",
        "data: List[Message] = []\n",
        "\n",
        "# 데이터 중 subject와 스팸 여부(is_spam)를 Message class에 넣는다\n",
        "# 해당 Message class 를 data에 append\n",
        "for filename in glob.glob(path):\n",
        "    is_spam = \"ham\" not in filename \n",
        "    with open(filename, errors='ignore') as email_file:\n",
        "        for line in email_file:\n",
        "            if line.startswith(\"Subject:\"):\n",
        "                subject = line.lstrip(\"Subject: \")\n",
        "                data.append(Message(subject, is_spam))\n",
        "                break "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKIJa3-xnnv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "50e0ae32-826d-48b9-cb51-f692d69acb1c"
      },
      "source": [
        "data[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Message(text='CNET NEWS.COM: The tech side of homeland defense\\n', is_spam=False),\n",
              " Message(text='Your Daily Dilbert 07/13/2002\\n', is_spam=False),\n",
              " Message(text='[Lockergnome Tech Specialist]  Frequent Format\\n', is_spam=False),\n",
              " Message(text='CNET DIGITAL DISPATCH: Mac zealots unite\\n', is_spam=False),\n",
              " Message(text='Yahoo! News Story - Top Stories\\n', is_spam=False),\n",
              " Message(text='firewalls Digest V1 #33\\n', is_spam=False),\n",
              " Message(text=\"DayTips' Poem-a-Day: 09/13/02\\n\", is_spam=False),\n",
              " Message(text=\"Classic Novels, Aesop's Fables, Issue 49\\n\", is_spam=False),\n",
              " Message(text='Personal Finance: Resolutions You Can Keep\\n', is_spam=False),\n",
              " Message(text='[Lockergnome Tech Specialist]  Geothermal Caffeine\\n', is_spam=False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWbkUhSZz9h7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, k: float = 0.5) -> None:\n",
        "        self.k = k  # smoothing factor\n",
        "\n",
        "        self.tokens: Set[str] = set()\n",
        "        self.token_spam_counts: Dict[str, int] = defaultdict(int)\n",
        "        self.token_ham_counts: Dict[str, int] = defaultdict(int)\n",
        "        self.spam_messages = self.ham_messages = 0\n",
        "\n",
        "    def train(self, messages: Iterable[Message]) -> None:\n",
        "        for message in messages:\n",
        "            # 메시지 자체를 스팸 여부에 따라 count\n",
        "            if message.is_spam:\n",
        "                self.spam_messages += 1\n",
        "            else:\n",
        "                self.ham_messages += 1\n",
        "\n",
        "            # 단어 추출 뒤 스팸 여부에 따라 count\n",
        "            for token in tokenize(message.text):\n",
        "                self.tokens.add(token)\n",
        "                if message.is_spam:\n",
        "                    self.token_spam_counts[token] += 1\n",
        "                else:\n",
        "                    self.token_ham_counts[token] += 1\n",
        "\n",
        "    def _probabilities(self, token: str) -> Tuple[float, float]:\n",
        "        # P (token | spam) 과 P(token | not spam) 을 return\n",
        "        spam = self.token_spam_counts[token]\n",
        "        ham = self.token_ham_counts[token]\n",
        "\n",
        "        p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
        "        p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\n",
        "\n",
        "        return p_token_spam, p_token_ham\n",
        "\n",
        "    def predict(self, text: str) -> float:\n",
        "        text_tokens = tokenize(text)\n",
        "        log_prob_if_spam = log_prob_if_ham = 0.0\n",
        "\n",
        "        # train 된 단어들(vocabulary 에 있는 단어들)을 loop\n",
        "        for token in self.tokens:\n",
        "            prob_if_spam, prob_if_ham = self._probabilities(token)\n",
        "\n",
        "            # voca 에 있는 단어가 예측하기 위한 단어 집합(text_tokens)에 있는 경우 \n",
        "            # probabilities를 통해 구한 확률에 log 처리후 더해 줌\n",
        "            if token in text_tokens:\n",
        "                log_prob_if_spam += math.log(prob_if_spam)\n",
        "                log_prob_if_ham += math.log(prob_if_ham)\n",
        "\n",
        "            # text_tokens 에 있는 단어가 voca 에는 없음\n",
        "            else:\n",
        "                log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
        "                log_prob_if_ham += math.log(1.0 - prob_if_ham)\n",
        "\n",
        "        prob_if_spam = math.exp(log_prob_if_spam)\n",
        "        prob_if_ham = math.exp(log_prob_if_ham)\n",
        "        return prob_if_spam / (prob_if_spam + prob_if_ham)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCb4X1ltywsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# train/test split\n",
        "train_messages, test_messages = split_data(data, 0.75)\n",
        "\n",
        "model = NaiveBayesClassifier()\n",
        "model.train(train_messages)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4RCid6U1R3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 테스트 데이터에 대한 predict\n",
        "predictions = [(message, model.predict(message.text)) for message in test_messages]\n",
        "\n",
        "# confusion matrix\n",
        "# 실제 스팸이 스팸이라고 예측 (True, True) (TP)\n",
        "# 햄이 스팸으로 예측 (False, True) (FP)\n",
        "# 햄이 햄으로 예측 (False, False) (TN)\n",
        "# 실제 스팸이 햄으로 예측 (True, False) (FN)\n",
        "confusion_matrix = Counter((message.is_spam, spam_probability > 0.5) for message, spam_probability in predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZlOoZWnBh9j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "09548581-5c4a-4eff-c51e-b29319477d31"
      },
      "source": [
        "confusion_matrix"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({(False, False): 675,\n",
              "         (False, True): 24,\n",
              "         (True, False): 51,\n",
              "         (True, True): 75})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARt8KRK1xAcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9d708452-44ca-4905-9591-306abd312a0e"
      },
      "source": [
        "cm = confusion_matrix\n",
        "# precision : TP / (TP + FP)\n",
        "# 스팸이라고 판단 한 것 중 실제 스팸인 비율\n",
        "print(cm[(True, True)] / (cm[(True, True)] + cm[(False, True)]))\n",
        "\n",
        "# recall : TP / (TP + FN)\n",
        "# 실제 스팸 중 스팸이라고 판단한 비율\n",
        "print(cm[(True, True)] / (cm[(True, True)] + cm[(True, False)]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7575757575757576\n",
            "0.5952380952380952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w0GH0ZK9s7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "79abdaf5-6319-4ac3-90e7-22e78952629b"
      },
      "source": [
        "def p_spam_given_token(token: str, model: NaiveBayesClassifier) -> float:\n",
        "    # naive bayse 를 통해 p(스팸 | 메시지가 해당 단어를 포함) 을 계산\n",
        "    prob_if_spam, prob_if_ham = model._probabilities(token)\n",
        "\n",
        "    return prob_if_spam / (prob_if_spam + prob_if_ham)\n",
        "\n",
        "# 스팸일 확률에 따라 메시지를 오름차순 정렬\n",
        "words = sorted(model.tokens, key=lambda t: p_spam_given_token(t, model))\n",
        "\n",
        "# 스팸일 확률이 가장 높은 메시지\n",
        "print(\"spammiest_words\", words[-10:])\n",
        "\n",
        "# 스팸일 확률이 가장 낮은 메시지\n",
        "print(\"hammiest_words\", words[:10])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spammiest_words ['clearance', 'account', 'per', 'sale', 'year', 'zzzz', 'systemworks', 'rates', 'money', 'adv']\n",
            "hammiest_words ['spambayes', 'users', 'zzzzteana', 'razor', 'sadev', 'ouch', 'perl', 'spam', 'bliss', 'selling']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6KhtT0I3nrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}